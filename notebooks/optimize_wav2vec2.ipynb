{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!pip3 install -U tf2onnx onnxruntime"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import tensorflow as tf"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "from wav2vec2 import Wav2Vec2ForCTC\n",
    "MODEL_ID = \"vasudevgupta/tf-wav2vec2-base-960h\"\n",
    "model = Wav2Vec2ForCTC.from_pretrained(MODEL_ID)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Downloading model weights from https://huggingface.co/vasudevgupta/tf-wav2vec2-base-960h ... Done\n",
      "Total number of loaded variables: 213\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "import soundfile as sf\n",
    "speech, _ = sf.read(\"../data/SA2.wav\")\n",
    "speech = tf.expand_dims(tf.constant(speech, dtype=tf.float32), 0)\n",
    "speech.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "TensorShape([1, 47104])"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "outputs = model(speech)\n",
    "print(outputs.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(1, 146, 32)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "import tf2onnx\n",
    "ONNX_PATH = \"onnx-wav2vec2.onnx\"\n",
    "\n",
    "input_signature = (tf.TensorSpec((None, 47104), tf.float32, name=\"speech\"),)\n",
    "_ = tf2onnx.convert.from_keras(model, input_signature=input_signature, output_path=ONNX_PATH)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "source": [
    "import onnxruntime as rt\n",
    "\n",
    "sess = rt.InferenceSession(ONNX_PATH)\n",
    "onnx_outputs = sess.run(None, {\"speech\": speech.numpy()})\n",
    "onnx_outputs"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[array([[[ 13.740026 , -26.97787  , -26.698689 , ...,  -6.6399283,\n",
       "           -8.961572 ,  -6.4920783],\n",
       "         [ 13.659376 , -27.625504 , -27.344852 , ...,  -7.2058935,\n",
       "           -9.226441 ,  -6.604441 ],\n",
       "         [ 13.97566  , -26.724403 , -26.42656  , ...,  -6.85717  ,\n",
       "           -8.794083 ,  -6.7176375],\n",
       "         ...,\n",
       "         [ 13.886351 , -26.631052 , -26.376377 , ...,  -5.5348268,\n",
       "           -8.127068 ,  -6.619991 ],\n",
       "         [ 13.886124 , -26.630331 , -26.37566  , ...,  -5.534939 ,\n",
       "           -8.126596 ,  -6.6206064],\n",
       "         [ 13.668737 , -27.154783 , -26.876873 , ...,  -6.8891983,\n",
       "           -9.146206 ,  -6.184449 ]]], dtype=float32)]"
      ]
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "onnx_outputs = sess.run(None, {\"speech\": speech.numpy()})\n",
    "print(onnx_outputs)\n",
    "print(\"TIME TAKEN:\", time.time() - start)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[array([[[ 13.740026 , -26.97787  , -26.698689 , ...,  -6.6399283,\n",
      "          -8.961572 ,  -6.4920783],\n",
      "        [ 13.659376 , -27.625504 , -27.344852 , ...,  -7.2058935,\n",
      "          -9.226441 ,  -6.604441 ],\n",
      "        [ 13.97566  , -26.724403 , -26.42656  , ...,  -6.85717  ,\n",
      "          -8.794083 ,  -6.7176375],\n",
      "        ...,\n",
      "        [ 13.886351 , -26.631052 , -26.376377 , ...,  -5.5348268,\n",
      "          -8.127068 ,  -6.619991 ],\n",
      "        [ 13.886124 , -26.630331 , -26.37566  , ...,  -5.534939 ,\n",
      "          -8.126596 ,  -6.6206064],\n",
      "        [ 13.668737 , -27.154783 , -26.876873 , ...,  -6.8891983,\n",
      "          -9.146206 ,  -6.184449 ]]], dtype=float32)]\n",
      "TIME TAKEN: 0.3857080936431885\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "start = time.time()\n",
    "outputs = model(speech)\n",
    "print(outputs)\n",
    "print(\"TIME TAKEN:\", time.time() - start)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tf.Tensor(\n",
      "[[[ 13.740425  -26.978495  -26.699314  ...  -6.6403112  -8.962097\n",
      "    -6.491789 ]\n",
      "  [ 13.659467  -27.625984  -27.34533   ...  -7.2062693  -9.226593\n",
      "    -6.604583 ]\n",
      "  [ 13.976038  -26.726124  -26.428267  ...  -6.8579597  -8.794957\n",
      "    -6.717271 ]\n",
      "  ...\n",
      "  [ 13.886277  -26.630238  -26.375546  ...  -5.534626   -8.126781\n",
      "    -6.619562 ]\n",
      "  [ 13.88648   -26.629833  -26.375141  ...  -5.534644   -8.126343\n",
      "    -6.620388 ]\n",
      "  [ 13.669438  -27.155434  -26.87751   ...  -6.8898835  -9.146654\n",
      "    -6.184311 ]]], shape=(1, 146, 32), dtype=float32)\n",
      "TIME TAKEN: 2.4164552688598633\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "@tf.function(jit_compile=True)\n",
    "def forward(speech):\n",
    "    return model(speech)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "start = time.time()\n",
    "outputs = forward(speech)\n",
    "print(outputs)\n",
    "print(\"TIME TAKEN:\", time.time() - start)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tf.Tensor(\n",
      "[[[ 13.740374  -26.979073  -26.699873  ...  -6.6408443  -8.962109\n",
      "    -6.4920826]\n",
      "  [ 13.659096  -27.625633  -27.34498   ...  -7.205656   -9.226397\n",
      "    -6.6042814]\n",
      "  [ 13.975779  -26.724964  -26.427097  ...  -6.857521   -8.794199\n",
      "    -6.7176   ]\n",
      "  ...\n",
      "  [ 13.886283  -26.630348  -26.375664  ...  -5.5347486  -8.12678\n",
      "    -6.620142 ]\n",
      "  [ 13.886637  -26.630585  -26.375904  ...  -5.53475    -8.126849\n",
      "    -6.6202025]\n",
      "  [ 13.66938   -27.155464  -26.877563  ...  -6.889975   -9.146458\n",
      "    -6.1848373]]], shape=(1, 146, 32), dtype=float32)\n",
      "TIME TAKEN: 0.8099558353424072\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "source": [
    "import numpy as np\n",
    "np.allclose(onnx_outputs, outputs.numpy(), atol=1e-2)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 49
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('gsoc': conda)"
  },
  "interpreter": {
   "hash": "ffe3d5ab944ba437a585ad4b729297f27b48afc64247938bbfcf4d0879de5a34"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}