{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "orig_nbformat": 4,
    "language_info": {
      "name": "python",
      "version": "3.8.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.10 64-bit ('gsoc': conda)"
    },
    "interpreter": {
      "hash": "ffe3d5ab944ba437a585ad4b729297f27b48afc64247938bbfcf4d0879de5a34"
    },
    "colab": {
      "name": "optimize_wav2vec2.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vasudevgupta7/gsoc-wav2vec2/blob/deploy/notebooks/wav2vec2_onnx.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bsARIDGQZsvw"
      },
      "source": [
        "# Wav2Vec2 ONNX\n",
        "\n",
        "In this notebook, we will be exporting TF Wav2Vec2 model into ONNX and will compare ONNX exported and TF model latency on CPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "byVPDd7kJoqS"
      },
      "source": [
        "!pip3 install -qU tf2onnx onnxruntime\n",
        "\n",
        "# TODO: update training-v2 by main after merge of training-v2\n",
        "!pip3 install -q git+https://github.com/vasudevgupta7/gsoc-wav2vec2@training-v2"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDiiDsXeJoqU"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qc-aR2AqJoqV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d46cb02-1240-439a-aeb9-84178aa79a89"
      },
      "source": [
        "from wav2vec2 import Wav2Vec2ForCTC\n",
        "\n",
        "model_id = \"vasudevgupta/gsoc-wav2vec2-base-960h\"\n",
        "model = Wav2Vec2ForCTC.from_pretrained(model_id)\n",
        "\n",
        "@tf.function(jit_compile=True)\n",
        "def jitted_forward(speech):\n",
        "    return model(speech)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading model weights from https://huggingface.co/vasudevgupta/gsoc-wav2vec2-base-960h ... Done\n",
            "Total number of loaded variables: 213\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2BtH4sYaFyS"
      },
      "source": [
        "from contextlib import contextmanager\n",
        "import time\n",
        "\n",
        "@contextmanager\n",
        "def timeit(prefix=\"Time taken:\"):\n",
        "  start = time.time()\n",
        "  yield\n",
        "  time_taken = time.time() - start\n",
        "  print(prefix, time_taken, \"seconds\")"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yd8FFmiZmgG",
        "outputId": "5c9f416e-80c9-4c28-da94-eaa7d56490e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!wget https://github.com/vasudevgupta7/gsoc-wav2vec2/raw/main/data/sample.wav"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-08-08 01:53:26--  https://github.com/vasudevgupta7/gsoc-wav2vec2/raw/main/data/sample.wav\n",
            "Resolving github.com (github.com)... 140.82.114.4\n",
            "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/vasudevgupta7/gsoc-wav2vec2/main/data/sample.wav [following]\n",
            "--2021-08-08 01:53:26--  https://raw.githubusercontent.com/vasudevgupta7/gsoc-wav2vec2/main/data/sample.wav\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 93638 (91K) [audio/wav]\n",
            "Saving to: ‘sample.wav’\n",
            "\n",
            "sample.wav          100%[===================>]  91.44K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2021-08-08 01:53:26 (6.41 MB/s) - ‘sample.wav’ saved [93638/93638]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RAbyByrnJoqW"
      },
      "source": [
        "import soundfile as sf\n",
        "AUDIO_MAXLEN = 246000\n",
        "\n",
        "speech, _ = sf.read(\"sample.wav\")\n",
        "speech = tf.constant(speech, dtype=tf.float32)[None, :AUDIO_MAXLEN]"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWGh7IbMJoqX",
        "outputId": "2464f930-dcbf-4dd5-bf52-397327f04d43",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import tf2onnx\n",
        "ONNX_PATH = \"onnx-wav2vec2.onnx\"\n",
        "\n",
        "input_signature = (tf.TensorSpec((None, speech.shape[1]), tf.float32, name=\"speech\"),)\n",
        "_ = tf2onnx.convert.from_keras(model, input_signature=input_signature, output_path=ONNX_PATH)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tf2onnx/tf_loader.py:662: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oozTycstJoqX"
      },
      "source": [
        "import onnxruntime as rt\n",
        "session = rt.InferenceSession(ONNX_PATH)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jyh-XEZdc4M",
        "outputId": "c214e17c-c555-4231-f397-7842759b2aa9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "onnx_outputs = session.run(None, {\"speech\": speech.numpy()})\n",
        "tf_outputs = jitted_forward(speech)\n",
        "\n",
        "np.allclose(onnx_outputs, tf_outputs.numpy(), atol=1e-2)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6Je3NISJoqY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "577d63fe-4c91-4663-e3f7-08a0ae13cdcd"
      },
      "source": [
        "with timeit(prefix=\"JIT Compiled Wav2vec2 time taken:\"):\n",
        "  jitted_forward(speech)\n",
        "\n",
        "with timeit(prefix=\"Eager mode time taken:\"):\n",
        "  model(speech)\n",
        "\n",
        "with timeit(prefix=\"ONNX-Wav2Vec2 time taken:\"):\n",
        "  session.run(None, {\"speech\": speech.numpy()})"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "JIT Compiled Wav2vec2 time taken: 1.9526395797729492 seconds\n",
            "Eager mode time taken: 1.234731674194336 seconds\n",
            "ONNX-Wav2Vec2 time taken: 0.795966386795044 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGM9cCnMJoqa"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}